{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 오늘 실습은 인공데이터가 아닌 실제데이터(mnist)로 딥러닝 구현!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이건 실행시켜야 하나........?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#-- 리스트 8-1-(1)\n",
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data() \n",
    "# x_train:입력벡터. 필기체 숫자 이미지 10만개 / y_train : 정수형 데이터(한 이미지 당 한 정수)\n",
    "# x_test / y_test  ==> ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.savez('mnist.npz',x_train=x_train, y_train=y_train,x_test=x_test,y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 여기서부터 실행시키면 됨!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "outfile = np.load('mnist.npz')\n",
    "x_train=outfile['x_train']\n",
    "y_train=outfile['y_train']\n",
    "x_test=outfile['x_test']\n",
    "y_test=outfile['y_test']\n",
    "y_test_origin = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - 리스트 8-1-(2)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(1, figsize=(12, 3.2))\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "plt.gray()\n",
    "for id in range(3):\n",
    "    plt.subplot(1, 3, id + 1)\n",
    "    img = x_train[id, :, :]  # 이미지 크기 : 28x28 / id : 각 이미지의 index. / : , : ==> 이미지(행렬구조)... 28x28모두 불러오겠다!\n",
    "    plt.pcolor(255 - img)  # 이미지가 그냥 5로만 보이지만,실제로는 5부분에 255에 가까운,흰 바탕 부분에 0에 가까운 값이 있음!==>반전시키기!\n",
    "    plt.text(18, 26, \"L:%d\" % y_train[id],  #y_train : 목적벡터(라벨값) /각 이미지에 대해서 레이블링(라벨) 되어있음 ==> 그래프 하단에 출력시키기\n",
    "             color='cornflowerblue', fontsize=14)\n",
    "    plt.xlim(0, 27)\n",
    "    plt.ylim(27, 0)\n",
    "    plt.grid('on', color='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- 리스트 8-1-(3)\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "x_train = x_train.reshape(60000, 784) # (A) 입력벡터가 열벡터로서 표현되도록, 입력으로 들어온 2차원 이미지데이터를 열벡터로 모양 바꾸기(6만개의 데이터를 28*28=784개의 노드 가진 세로 열벡터로!!)\n",
    "x_train = x_train.astype('float32') # (B) astype함수 호출시켜서 int(정수형) 타입을 float(실수형)으로 바꾸기\n",
    "x_train = x_train / 255 # (C) 255로 나누면 0~1사이의 값으로 정규화됨(normalization)\n",
    "num_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train, num_classes) # (D) 원핫코드로 바꾸기!(~~의 to_categorical 사용하면댐) ==> 10개의 출력(0000 or 1)으로 바꾸되, 원핫코드로 바꿔주기!\n",
    "\n",
    "\n",
    "x_test = x_test.reshape(10000, 784) # test set은 10000개 (아까 위에서 훈련집합은 60000개)\n",
    "x_test = x_test.astype('float32')\n",
    "x_test = x_test / 255\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- 리스트 8-1-(4) ==> p.326의 그림 8-2 : 2층 MLP 구현하기\n",
    "np.random.seed(1)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "model = Sequential() # (A) 직렬구조의 네트워크...쓸때... Sequential 이라는 객체 써야함(객체생성)\n",
    "model.add(Dense(16, input_dim=784, activation='sigmoid')) # (B)은닉층 (노드)수?를 16개로, 은닉층의 활성함수로 시그모이드 쓰기 / ***Dense(200)으로 바꿔보기! ==> 무작정 늘린다고 성능 좋아지는 거 아니다~\n",
    "\n",
    "#model.add(Dense(12, activation='sigmoid')) # *** 쉅시간에 네트워크 구조 하나 추가해봄!! 네트워크 바꿔보기!! ==> 좀 시간걸리겟지..훈련시켜보기 ==> 오히려 성능(Test Accuracy) 떨어짐..!*** \n",
    "\n",
    "model.add(Dense(10, activation='softmax')) # (C) 출력층 노드 수를 10개로, 출력층의 활성함수로 소프트맥스 쓰기\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',  # 교차엔트로피로 쓰겠다(비용함수??) / compile함수를 이용해서 .....정의???ㅠㅠ\n",
    "optimizer=Adam(), metrics=['accuracy']) # (D)훈련이 잘 되었는지를 측정하는 measure로서 accuracy쓰겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 여기까지는 기본 셋팅한 것. (구성요소들 정의)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- 리스트 8-1-(5)\n",
    "import time\n",
    "\n",
    "\n",
    "startTime = time.time()\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=1000,  #(트레이닝에 쓰이는 입력벡터, 목적벡터, 각각의 트레이닝 데이터에 대해서 10번 돌리겠다(순회), \n",
    "                    verbose=1, validation_data=(x_test, y_test)) # (A)\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print(\"Computation time:{0:.3f} sec\".format(time.time() - startTime)) # 실제 수행 시간 알 수 있음.\n",
    "\n",
    "#결과보면 100개 중에서 89개 맞췄다는 걸 알수있음.\n",
    "#Computation time : 약 3초정도밖에 안걸림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- 리스트 8-1-(6)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "plt.figure(1, figsize=(10, 4))\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='training', color='black')\n",
    "plt.plot(history.history['val_loss'], label='test',\n",
    "         color='cornflowerblue')\n",
    "plt.ylim(0, 10)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='training', color='black')\n",
    "plt.plot(history.history['val_accuracy'],label='test', color='cornflowerblue')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.show()\n",
    "\n",
    "# 첫번째 : 검정선은 loss함수의 에러값 / 파란색은 test 데이터의 검증값  ==>  둘다 0으로 수렴하고 있으니까 잘 훈련되고 있다는 걸 알 수 있음.(오버피팅 안일어남)\n",
    "# 두번째 그래프도 마찬가지!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- 리스트 8-1-(7)\n",
    "def show_prediction():\n",
    "    n_show = 96\n",
    "    y = model.predict(x_test) # (A)\n",
    "    plt.figure(2, figsize=(12, 8))\n",
    "    plt.gray()\n",
    "    for i in range(n_show):\n",
    "        plt.subplot(8, 12, i + 1)\n",
    "        x = x_test[i, :]  # 아까 위에서 데이터들을 다 직렬화시켰음(열벡터로) ==> 이거를 다시 28*28 이미지 형태로 바꿔주는 것.\n",
    "        x = x.reshape(28, 28) # 28*28 크기의 이미지 형태로 다시 변환시키기~\n",
    "        plt.pcolor(1 - x)  # 반전시키기. 0~1사이의 값을 x가 갖기 때문에 1에서 빼주면... 반전된 값.\n",
    "        wk = y[i, :]\n",
    "        prediction = np.argmax(wk)\n",
    "        plt.text(18, 25.5,\"%d\" % y_test_origin[i],fontsize=12) # y_test_origin[i] : 맨위에서 y_test.copy() 헀었음. 여기에서 읽어들이는거..\n",
    "        plt.text(22, 25.5,\"%d\" % prediction,fontsize=12)\n",
    "        if prediction != np.argmax(y_test[i, :]):\n",
    "            plt.plot([0, 27], [1, 1], color='cornflowerblue', linewidth=5)\n",
    "        plt.xlim(0, 27)\n",
    "        plt.ylim(27, 0)\n",
    "        plt.xticks([], \"\")\n",
    "        plt.yticks([], \"\")\n",
    "#-- 메인\n",
    "show_prediction()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 이정도면 훌륭!! 대부분 잘 분류함. 근데 요즘에는 거의 99.9% 잘 분류해서 이정도가지고는 실용화하지는 못함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#-- 리스트 8-1-(8)\n",
    "np.random.seed(1)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=784, activation='relu')) # (A)활성함수로 렐루함수로 쓰기(이거 하나만 바꿨는데도 엄청난 효과가!!)\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "\n",
    "startTime = time.time()\n",
    "history = model.fit(x_train, y_train, batch_size=1000, epochs=10,\n",
    "                    verbose=1, validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print(\"Computation time:{0:.3f} sec\".format(time.time() - startTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 리스트 8-1-(9)\n",
    "show_prediction()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- 리스트 8-1-(10)\n",
    "# 1층째의 무게 시각화\n",
    "w = model.layers[0].get_weights()[0] # layers[0]이면 첫번째 히든레이어(은닉층), get_weights()[0] 에서 0이아니라 1이면 바이어스 노드까지..?포함한 가중치..?\n",
    "plt.figure(1, figsize=(12, 3))\n",
    "plt.gray()\n",
    "plt.subplots_adjust(wspace=0.35, hspace=0.5)\n",
    "for i in range(16):\n",
    "    plt.subplot(2, 8, i + 1)\n",
    "    w1 = w[:, i] # 하나의 히든노드에 연결되어있는 입력노드의 가중치들. 총 784개(28*28)==입력노드의 차원. 열벡터!\n",
    "    w1 = w1.reshape(28, 28) # 열벡터를 28*28의 형태로 변환시키기~\n",
    "    plt.pcolor(-w1)\n",
    "    plt.xlim(0, 27)\n",
    "    plt.ylim(27, 0)\n",
    "    plt.xticks([], \"\")\n",
    "    plt.yticks([], \"\")\n",
    "    plt.title(\"%d\" % i)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- 리스트 8-2-(1)\n",
    "import numpy as np\n",
    "# from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "outfile = np.load('mnist.npz')\n",
    "x_train=outfile['x_train']\n",
    "y_train=outfile['y_train']\n",
    "x_test=outfile['x_test']\n",
    "y_test=outfile['y_test']\n",
    "y_test_origin = y_test.copy()\n",
    "\n",
    "\n",
    "x_train = x_train.reshape(60000, 28, 28, 1) # 3차원 *텐서*로 이미지를 표현! 28*28크기의 이미지가 1개 있는 것. 그런게 6만개 있음! 이미지!\n",
    "x_test = x_test.reshape(10000, 28, 28, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255  # 0~1사이의 값을 갖도록 정규화\n",
    "x_test /= 255\n",
    "num_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train, num_classes) # 목적벡터를 원핫코드 형식으로 바꿔주기\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- 리스트 8-2-(2)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "id_img = 2\n",
    "\n",
    "myfil1 = np.array([[1/9, 1/9, 1/9],\n",
    "                   [1/9, 1/9, 1/9],\n",
    "                   [1/9, 1/9, 1/9]], dtype=float) # (A) average filter : 각 요소들을 9분의1씩 해주는 것 == 평균내는 것 == **블러링 효과**\n",
    "myfil2 = np.array([[0, -1, 0],\n",
    "                   [-1, 5, 1],\n",
    "                   [0, -1, 0]], dtype=float) # (B) sharping filter : 주변보다 현재 가운데 픽셀을 두드러지게 하는 것 == **샤프닝 효과**\n",
    "\n",
    "#myfil1 = np.array([[-1, -1, -1],\n",
    "#                   [0, 0, 0],\n",
    "#                   [1, 1, 1]], dtype=float) # (A) horizontal edge filter : 교수님이 책과는 좀 다르게, 좀 더 일반적인 커널! ==> **수평~**\n",
    "\n",
    "# myfil2 = np.array([[-1, 0, 1],\n",
    "#                   [-1, 0, 1],\n",
    "#                   [-1, 0, 1]], dtype=float) # (B) vertical edge filter : **수직~**\n",
    "\n",
    "\n",
    "x_img = x_train[id_img, :, :, 0]\n",
    "img_h = 28\n",
    "img_w = 28\n",
    "x_img = x_img.reshape(img_h, img_w)  # 28*28 2차원 행렬로 입력 이미지를 가져옴..?\n",
    "out_img1 = np.zeros_like(x_img)  # 이미지 각각에 대해서 출력값을 저장. 원래 크기인 28*28 형태로..?\n",
    "out_img2 = np.zeros_like(x_img)\n",
    "\n",
    "# 필터 처리\n",
    "for ih in range(img_h - 3):\n",
    "    for iw in range(img_w - 3):\n",
    "        img_part = x_img[ih:ih + 3, iw:iw + 3]  # 이미지의 일부(커널만큼) 떼어오는 것 ==> 입력으로ㄱㄱ해서 컨볼루션 / 텐서 구조로다가 이미지를 변환시켜놨었음. / x_img는 이미지 자체(2차원) / ih:ih+3  ==> 만약 ih=0이면 0,1,2 까지만! 이미지에서 뗴어오기!\n",
    "        out_img1[ih + 1, iw + 1] = \\\n",
    "            np.dot(img_part.reshape(-1), myfil1.reshape(-1))# 내적시켜서 output img(out_img)에 저장하는거랑 같음! (그냥 행렬 요소 곱 하는거랑...)\n",
    "        out_img2[ih + 1, iw + 1] = \\\n",
    "            np.dot(img_part.reshape(-1), myfil2.reshape(-1)) \n",
    "\n",
    "\n",
    "# - 표시\n",
    "plt.figure(1, figsize=(12, 3.2))\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "plt.gray()\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.pcolor(1 - x_img)\n",
    "plt.xlim(-1, 29)\n",
    "plt.ylim(29, -1)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.pcolor(-out_img1)\n",
    "plt.xlim(-1, 29)\n",
    "plt.ylim(29, -1)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.pcolor(-out_img2)\n",
    "plt.xlim(-1, 29)\n",
    "plt.ylim(29, -1)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 두번째 : 블러링 효과\n",
    "# 세번째 : 샤프닝 효과 / 바깥보녀 0덧대기(zero-padding)안해서 이미지 사이즈가 줄음!(테두리부분 사라짐)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- 리스트 8-2-(3)  ==>  케라스를 쓰면 네트워크를 구성하는게 직관적. 쉬움.\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "import time\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(8, (3, 3), padding='same',  # 층하나 쌓은 것!(add). 컨볼루션 함수. 3x3짜리 커널, padding:입력특징맵의 사이즈와 달라지지 않도록 제로패딩하겠다, \n",
    "                 input_shape=(28, 28, 1), activation='relu')) # (A)input_shape : 입력이미지사이즈(3차원행렬), activation:활성함수\n",
    "model.add(Flatten()) # (B) 직렬화 하는 과정! 층을 하나 만든다기 보다는 변환하는 것. 마지막에 분류 위한 f-c(완전연결층)에 연결하기 위해서!!\n",
    "model.add(Dense(10, activation='softmax'))  #Dense함수(f-c),  : 10개노드(0~9필기체 숫자 인식하는거라서)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),  # optimizer : Adam 알고리즘(이번주이론시간에배움)\n",
    "              metrics=['accuracy']) # accuracy : 참,거짓 판별한 것 중 참으로 판별한 것의 개수의 비율. 이걸로 성능 평가함.(성능평가기준 : accuracy, recall) \n",
    "startTime = time.time()\n",
    "history = model.fit(x_train, y_train, batch_size=1000, epochs=20,  # fit함수 : training하는 과정. (입력벡터, 목적벡터, 배치사이즈1000(미니배치), 에포크 20세대,)\n",
    "                    verbose=1, validation_data=(x_test, y_test)) #verbose :????, 검증할 목적으로 테스트데이터집합 씀.\n",
    "score = model.evaluate(x_test, y_test, verbose=0)  # evaluate : 마지막에 성능 확인하는 작업.\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print(\"Computation time:{0:.3f} sec\".format(time.time() - startTime))\n",
    "\n",
    "# 결과 ==> Test accuracy: 0.9707 ==> DMLP로 했을 때 0.95? 94? 였는데, CNN쓰면 정확도가 훨씬 올라감! (CNN만 썼을 때...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- 리스트 8-1-(7)\n",
    "def show_prediction():\n",
    "    n_show = 96\n",
    "    y = model.predict(x_test) # (A)\n",
    "    plt.figure(2, figsize=(12, 8))\n",
    "    plt.gray()\n",
    "    for i in range(n_show):\n",
    "        plt.subplot(8, 12, i + 1)\n",
    "        x = x_test[i, :]\n",
    "        x = x.reshape(28, 28)\n",
    "        plt.pcolor(1 - x)\n",
    "        wk = y[i, :]\n",
    "        prediction = np.argmax(wk)\n",
    "        plt.text(22, 25.5, \"%d\" % prediction, fontsize=12)\n",
    "        if prediction != np.argmax(y_test[i, :]):\n",
    "            plt.plot([0, 27], [1, 1], color='cornflowerblue', linewidth=5)\n",
    "        plt.xlim(0, 27)\n",
    "        plt.ylim(27, 0)\n",
    "        plt.xticks([], \"\")\n",
    "        plt.yticks([], \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 리스트 8-2-(4)\n",
    "show_prediction()\n",
    "plt.show()\n",
    "\n",
    "# 전체에서 틀린게 2개밖에 없음!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리스트 8-2-(5)\n",
    "plt.figure(1, figsize=(12, 2.5))\n",
    "plt.gray()\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.2)\n",
    "plt.subplot(2, 9, 10)\n",
    "id_img = 12\n",
    "x_img = x_test[id_img, :, :, 0]\n",
    "img_h = 28\n",
    "img_w = 28\n",
    "x_img = x_img.reshape(img_h, img_w)\n",
    "plt.pcolor(-x_img)\n",
    "plt.xlim(0, img_h)\n",
    "plt.ylim(img_w, 0)\n",
    "plt.xticks([], \"\")\n",
    "plt.yticks([], \"\")\n",
    "plt.title(\"Original\")\n",
    "\n",
    "\n",
    "w = model.layers[0].get_weights()[0] # (A)\n",
    "max_w = np.max(w)\n",
    "min_w = np.min(w)\n",
    "for i in range(8):\n",
    "    plt.subplot(2, 9, i + 2)\n",
    "    w1 = w[:, :, 0, i]\n",
    "    w1 = w1.reshape(3, 3)\n",
    "    plt.pcolor(-w1, vmin=min_w, vmax=max_w)\n",
    "    plt.xlim(0, 3)\n",
    "    plt.ylim(3, 0)\n",
    "    plt.xticks([], \"\")\n",
    "    plt.yticks([], \"\")\n",
    "    plt.title(\"%d\" % i)\n",
    "    plt.subplot(2, 9, i + 11)\n",
    "    out_img = np.zeros_like(x_img)\n",
    "    # 필터 처리\n",
    "    for ih in range(img_h - 3):\n",
    "        for iw in range(img_w - 3):\n",
    "            img_part = x_img[ih:ih + 3, iw:iw + 3]\n",
    "            out_img[ih + 1, iw + 1] = \\\n",
    "            np.dot(img_part.reshape(-1), w1.reshape(-1))\n",
    "    plt.pcolor(-out_img)\n",
    "    plt.xlim(0, img_w)\n",
    "    plt.ylim(img_h, 0)\n",
    "    plt.xticks([], \"\")\n",
    "    plt.yticks([], \"\")\n",
    "plt.show()\n",
    "\n",
    "# 첫번째 행 : 8개의 커널의 값들을 이미지로써 보여준 것! 검은색이 높은값(큰값), 흰색이 낮은값(작은값..0쪽)\n",
    "# ==> 이런 커널들을 사람이 만드는 것이 아니라, 네트워크가 자동적으로 생성한 것. 과거에는 이렇게 학습을 통해서가 아니라 인간이 직접 찾음..\n",
    "\n",
    "# 두번째 행 : 입력한 원본이미지(9)에 각 커널들을 적용했을 때 나타나는 이미지. 8개의 특징맵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리스트 8-2-(6) ==> 몇 줄 안되지만, 네트워크 구현하고 학습까지 수행한 코드!\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "import time\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3, 3),\n",
    "                 input_shape=(28, 28, 1), activation='relu')) #1번째 층 : 컨볼루션 층. 3x3짜리 커널 16개쓰겠다, 입력벡터의 크기(28x28x1..텐서구조 쓰기위해), 활성함수로 렐루함수\n",
    "model.add(Conv2D(32, (3, 3), activation='relu')) #2번째 층 : 컨볼루션 층. 3x3짜리 커널 32개 쓰겠다.\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) # (A) 3번째 층 : 최대풀링 층\n",
    "model.add(Conv2D(64, (3, 3), activation='relu')) #4번째 층 : 컨볼루션 층\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) # (B)5번째 층 : 최대풀링 층\n",
    "model.add(Dropout(0.25)) # (C) 그다음에 드롭아웃 적용(규제) ==> 중간층 노드들의 p=0.25만큼만 가지고 학습시키겠다!\n",
    "\n",
    "model.add(Flatten()) # f-c로 넘어가기 전에 열벡터로 쭉 펴는 플랫튼 과정 필요.\n",
    "model.add(Dense(128, activation='relu')) # Dense함수..??\n",
    "model.add(Dropout(0.25)) # (D) 다시한번 규제. p=0.25\n",
    "model.add(Dense(num_classes, activation='softmax')) # num_classes = 10 ==> 출력 노드를 10개로 정해줌. 마지막 활성함수는 소프트맥스로 쓰겠다\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy']) # 목적(비용)함수로 교차엔트로피쓰겠다, Adam이라는 알고리즘쓰겠다, 성능 측정 판단 기준은 accuracy 쓰겠다\n",
    "\n",
    "\n",
    "startTime = time.time()\n",
    "\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=1000, epochs=20, \n",
    "                    verbose=1, validation_data=(x_test, y_test)) # fit함수 써서 실제로 트레이닝.학습. 배치사이즈, 에포크,,, 중간과정(verbose?)\n",
    "\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0) # 마지막에 검증하는 단계\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print(\"Computation time:{0:.3f} sec\".format(time.time() - startTime))\n",
    "\n",
    "# 아래 결과들 Epoch(에포크) 마다 각각 봐보면, 한 에포크 당 40초정도 걸림... 20에포크 다하면 한 800초(10여분 걸림..)\n",
    "# 점점 acc(accuracy) 올라감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 리스트 8-2-(7)\n",
    "show_prediction()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
